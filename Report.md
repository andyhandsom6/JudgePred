# 刑罚预测模型
*李安齐*

*北京大学元培学院，2300017432*

## 一、方法

本次实验，我们选择了一个思路简单清晰的方法：通过对基座大模型进行**监督微调**（SFT），让模型获得预测罪名、刑期的能力，从而解决刑罚预测问题。

选择这个方法而非zero-shot地提示大模型，主要是因为后者难以充分利用训练数据，且耗时更长、成本高昂。

考虑到对于Task1和Task2，分别有较长的罪名文件`charges.json`与法律条文`articles.json`，在面临上述挑战的情况下，与其费办法把它们通过某种方式塞入提示词，不如直接通过SFT，令模型隐式地学习到这些内容。

于是，我们对Task1和Task2提出通用的方法：将训练数据中的犯罪事实、被告人信息写成结构化的提示词，作为训练的输入；将训练数据的`outcomes`一栏作为监督信号，令模型直接输出json格式的判罚结果。

## 二、实现

### 基线模型实现
我们采用**Qwen3-0.6B**作为基座模型，在一个有8张A100的远程服务器上训练大约15分钟，得到我们的模型。模型的超参数如下：

| 参数             | 值     |
|------------------|--------|
| 批规模       | 1      |
| 梯度积累步数 | 8      |
| 学习率    | 5e-5   |
| epoch           | 3      |
| 最大输入token       | 5120   |
| 参数精度 | torch.bfloat16 |

超参数没有经过任何精细的调整。这可能是改进模型能力的一个方向。同时，由于受到显存限制，采用了不够合理的批规模（经验上看，过小）。

对于实验数据，我们首先进行结构化的预处理。通过以下代码构造提示词：
```python
def create_prompt(example, charges):
    fact = example["fact"]
    defendants = example["defendants"]
    prompt = f"""【案件事实】
{fact}
【被告人信息】
{defendants}
"请根据上述案件事实，直接以json的形式给出每名被告人的罪名和刑期（单位：月）。"
"""
    return prompt
```

然后，我们利用`accelerate`包调度多卡进行训练。我们按照Qwen3官方文档的引导，通过构造token序列，关闭了Qwen3的深度思考功能。
更多的细节可以在代码中找到。

下面展开介绍我们在基线模型基础上所做的3个改进：

### 改进1：数据增广（针对两个Task）

当前的方法，对于一个人多个罪名的情况，如果预测错了顺序，是会被loss惩罚的。然而实际的metric，是对顺序没有要求的（事实上也没有顺序）。

所以，我们采取一个简单的数据增广：每次训练代码收集数据时，随机打乱一个人的罪名顺序。这样，可以让模型学到罪名的顺序无关性。

### 改进2：学习法条知识（针对Task 2）

对于Task2，我们希望模型可以充分利用法条知识。所以我们在训练数据中加入法条知识，让模型对它充分掌握。
一个容易想到的方案是：
- 输入：“请**默写**刑法第xx条内容”
- 输出：“xxx（完整内容）”

这样可以让因果模型学习到法条的完整内容。我们把它当作一个基线。

在此基础上，我们仔细观察法条语料，用下面的方法开发出了**更合理**的数据集：
1. 查找所有关键词`“的，”`，我们发现在这个关键词后面往往会给出具体的判罚内容，例如：
   ```
   ...贻误事故抢救，情节严重的，处三年以下有期徒刑或者拘役；...
   ```
   学习这些知识可以增强模型的判罚能力。所以我们查找所有语料中所有的关键词，以它为界，分割语料，将关键词以前的部分作为prompt，关键词以后的部分作为label，加入训练数据。
2. 查找所有关键词`“年以”`，我们发现这个关键词一定表示刑罚时长，例如：
   ```
   ...处三年以下有期徒刑或者拘役...
   ```
   我们把所有该关键词前的年份，都替换成数字表示的月份。例如，以上语料会被改为：
   ```
   ...处36个月以下有期徒刑或者拘役...
   ```
   这样，与模型预测的结果格式保持一致，让法条预测和刑罚预测成为同源的任务，使得模型更加容易收敛。


### 改进3：长文本压缩（针对两个Task）

我们观察到，超过30%的实验数据在训练中由于分词后token数量超过阈值，会被截断。一个可行的方法，是预先用LLM处理数据，对过长的文本进行概括，将其token数量降低至阈值以下。

为了节省时空消耗，我们采用Qwen3-0.6B，用如下提示词来清洗数据：

```python
prompt = f"""
假设你是一个法律专家。请你将以下犯罪事实压缩到**2000**字左右。要求：
1）保留可以用来断定每个犯罪嫌疑人**罪名**和**量刑**的关键信息；
2）不要对**嫌疑犯**的人名进行任何程度的改动与删减；
3）**可以**删去与判定罪行无关的证据收集、调查过程等内容与人物；
4）不需要给出“好的”之类的答复，而是**直接输出**整理后的事实。
5）所有输出严禁换行，严禁使用Markdown语法
6）所有内容输出在同一行，输出纯文本。
以下是犯罪事实。
{fact}
"""
```




## 三、实验

我们直接展示消融实验的结果：

| 模型 | 任务1 | 任务2 |
| --- | --- | --- |
| 基线 |  0.823 | 0.169 |
|+改进1|    |    |
|+改进2|  0.817 | 0.176 |
|+改进3|    |    |
|最终|||

其中，最终版的模型，对于任务1，我们施加改进1、改进3；对于任务2，我们施加所有三个改进。

对于改进2，我们拿最终方案、简单方案（仅默写），与基线做比较。
|模型|任务2|
|---|---|
|基线|0.1715|
|简单方案|0.1618|
|最终方案|**0.1762**|

## 四、分析

### 改进1


### 改进2


### 改进3

此外，在实验过程中，我们还观察到一些现象：
对于Task2，如果我们不在提示词里明确指出“请预测罪名和**刑期**”，模型有的时候不能正常地输出json格式的结果，而是会输出不符合格式要求的字符。这本来不应该出现，因为SFT理应让模型学会给出严格符合格式的输出要求。我们推测，这种现象的原因可能是：
- 训练样本太少
- epoch、lr等超参数设置不够合理

导致模型学得不够好、或者不够充分。
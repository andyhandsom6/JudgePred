# 刑罚预测模型
*李安齐*

*北京大学元培学院，2300017432*

## 一、方法

本次实验，我们选择了一个思路简单清晰的方法：通过对基座大模型进行**监督微调**（SFT），让模型获得预测罪名、刑期的能力，从而解决刑罚预测问题。

选择这个方法而非zero-shot地提示大模型，主要是因为后者难以充分利用训练数据，且耗时更长、成本高昂。

考虑到对于Task1和Task2，分别有较长的罪名文件`charges.json`与法律条文`articles.json`，在面临上述挑战的情况下，与其费办法把它们通过某种方式塞入提示词，不如直接通过SFT，令模型隐式地学习到这些内容。

于是，我们对Task1和Task2提出通用的方法：将训练数据中的犯罪事实、被告人信息写成结构化的提示词，作为训练的输入；将训练数据的`outcomes`一栏作为监督信号，令模型直接输出json格式的判罚结果。

## 二、实现

### 基线模型实现
我们采用**Qwen3-0.6B**作为基座模型，在一个有8张A100的远程服务器上训练大约15分钟，得到我们的模型。模型的超参数如下：

| 参数             | 值     |
|------------------|--------|
| 批规模       | 1      |
| 梯度积累步数 | 8      |
| 学习率    | 5e-5   |
| epoch           | 3      |
| 最大输入token       | 5120   |
| 参数精度 | torch.bfloat16 |

超参数没有经过任何精细的调整。这可能是改进模型能力的一个方向。同时，由于受到显存限制，采用了不够合理的批规模（经验上看，过小）。

对于实验数据，我们首先进行结构化的预处理。通过以下代码构造提示词：
```python
def create_prompt(example, charges):
    fact = example["fact"]
    defendants = example["defendants"]
    prompt = f"""【案件事实】
{fact}
【被告人信息】
{defendants}
"请根据上述案件事实，直接以json的形式给出每名被告人的罪名和刑期（单位：月）。"
"""
    return prompt
```

然后，我们利用`accelerate`包调度多卡进行训练。我们按照Qwen3官方文档的引导，通过构造token序列，关闭了Qwen3的深度思考功能。
更多的细节可以在代码中找到。

下面展开介绍我们在基线模型基础上所做的3个改进：

### 改进1：数据增广（针对两个Task）

当前的方法，对于一个人多个罪名的情况，如果预测错了顺序，是会被loss惩罚的。然而实际的metric，是对顺序没有要求的（事实上也没有顺序）。

所以，我们采取一个简单的数据增广：每次训练代码收集数据时，随机打乱一个人的罪名顺序。这样，可以让模型学到罪名的顺序无关性。

### 改进2：学习法条知识（针对Task 2）

对于Task2，我们希望模型可以充分利用法条知识。所以我们在训练数据中加入法条知识，让模型对它充分掌握。
一个容易想到的方案是：
- 输入：“请**默写**刑法第xx条内容”
- 输出：“xxx（完整内容）”

这样可以让因果模型学习到法条的完整内容。我们把它当作一个基线。

在此基础上，我们仔细观察法条语料，用下面的方法开发出了**更合理**的数据集：
1. 查找所有关键词`“的，”`，我们发现在这个关键词后面往往会给出具体的判罚内容，例如：
   ```
   ...贻误事故抢救，情节严重的，处三年以下有期徒刑或者拘役；...
   ```
   学习这些知识可以增强模型的判罚能力。所以我们查找所有语料中所有的关键词，以它为界，分割语料，将关键词以前的部分作为prompt，关键词以后的部分作为label，加入训练数据。
2. 查找所有关键词`“年以”`，我们发现这个关键词一定表示刑罚时长，例如：
   ```
   ...处三年以下有期徒刑或者拘役...
   ```
   我们把所有该关键词前的年份，都替换成数字表示的月份。例如，以上语料会被改为：
   ```
   ...处36个月以下有期徒刑或者拘役...
   ```
   这样，与模型预测的结果格式保持一致，让法条预测和刑罚预测成为同源的任务，使得模型更加容易收敛。


### 改进3：长文本压缩（针对两个Task）

我们观察到，超过30%的实验数据在训练中由于分词后token数量超过阈值，会被截断。一个可行的方法，是预先用LLM处理数据，对过长的文本进行概括，将其token数量降低至阈值以下。

为了节省时空消耗，我们采用Qwen3-0.6B，用如下提示词来清洗数据：

```python
prompt = f"""
假设你是一个法律专家。请你将以下犯罪事实压缩到**2000**字左右。要求：
1）保留可以用来断定每个犯罪嫌疑人**罪名**和**量刑**的关键信息；
2）不要对**嫌疑犯**的人名进行任何程度的改动与删减；
3）**可以**删去与判定罪行无关的证据收集、调查过程等内容与人物；
4）不需要给出“好的”之类的答复，而是**直接输出**整理后的事实。
5）所有输出严禁换行，严禁使用Markdown语法
6）所有内容输出在同一行，输出纯文本。
以下是犯罪事实。
{fact}
"""
```

处理前后的数据，提示词平均token数量变化：
|处理前|处理后|
|---|---|
|1179.6 |939.3|


## 三、实验

我们直接展示消融实验的结果：

| 模型 | 任务1 | 任务2 |
| --- | --- | --- |
| 基线 |  0.823 | 0.169 |
|+改进1|  0.824  | 0.171   |
|+改进2|  0.817 | 0.176 |
|+改进3|  0.831 | 0.173   |
|最终| 0.840 | 0.176 |

其中，最终版的模型，对于任务1，我们施加改进1、改进3；对于任务2，我们施加所有三个改进。

对于改进2，我们拿最终方案、简单方案（仅默写），与基线做比较。
|模型|任务2|
|---|---|
|基线|0.1715|
|简单方案|0.1618|
|最终方案|**0.1762**|

## 四、分析

### 改进1：数据增广（针对两个Task）

实验表明，改进1有一定的效果，但不够显著。我们认为，改进1可以让模型一定程度上学习到判决的顺序无关性；但是，由于多判罚的语料本身就占比较少（4%左右），加上epoch数等参数潜在的设计不合理，导致该改进的提升不够显著。

### 改进2：学习法条知识（针对Task 2）

实验表明，改进2对Task 1有一定副作用，对Task 2有显著的正向影响。

前者的原因：法条知识，对Task 1任务本身，从道理上讲并没有增益，因为做出罪名的判罚不依赖法条，模型完全可以隐式地学到所有的罪名；反而，法条知识的引入让模型收敛变得更加困难，loss有一部分被法条分担，梯度对罪名预测的收敛程度不够。

后者的原因：加入法条知识，尤其是精细处理过后的法条知识进行cotune，由于语料经过了任务维度上的对齐，可以显著地提升数据丰富性，从而帮助Task 2取得更高的表现。


### 改进3：长文本压缩（针对两个Task）

实验表明，改进3对两个Task均有增益作用。

我们也观察到，由于基座模型Qwen3-0.6B的能力问题，清洗过后的数据还是会出现
- 内容残缺
- 字数远远超出限制

等问题。这很可能是导致模型不能获得更好效果的原因。

### 其他分析

在实验过程中，我们还观察到一些现象：在改变实验条件时，虽然epoch数和lr等关键参数没有改、只是更改了数据，但模型有时会失去正常输出json格式结果的能力，输出不符合格式要求的字符。这本来不应该出现，因为SFT理应让模型学会给出严格符合格式的输出要求。我们推测，这种现象的原因可能是：
- 训练样本太少
- epoch、lr等超参数设置不够合理

导致模型未能充分收敛。


# 结论

本次实验，我们通过大模型在语料上SFT，针对出现的问题提出三点改进方案，增强了模型执行刑罚预测任务的能力。更进一步的研究，可以着手于：
- 规模化（数据+模型）、参数调优
- 系统解决顺序无关性问题
- 对年份的数字预测采取更加合理的监督方式
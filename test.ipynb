{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "41281142",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yunpeng/anaconda3/envs/anqi-lab/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Loading checkpoint shards: 100%|██████████| 7/7 [00:05<00:00,  1.33it/s]\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "model_name = \"/home/yunpeng/lianqi/fnlp/JudgePred/model_zoo/Qwen3-8B\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    torch_dtype=\"auto\",\n",
    "    device_map=\"auto\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca33d282",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c582e3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "template loaded\n",
      "finish generating\n",
      "thinking content: \n",
      "content: A large language model (LLM) is an advanced type of artificial intelligence that is trained on vast amounts of text data to understand and generate human-like text. These models can perform a wide range of tasks, such as answering questions, writing stories, coding, and translating languages. LLMs are built using deep learning techniques, particularly transformer architectures, which allow them to process and generate text efficiently. Their ability to comprehend and produce natural language makes them powerful tools in various applications, from customer service chatbots to content creation and research assistance.\n"
     ]
    }
   ],
   "source": [
    "# prepare the model input\n",
    "prompt = \"Give me a short introduction to large language model.\"\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": prompt}\n",
    "]\n",
    "text = tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    tokenize=False,\n",
    "    add_generation_prompt=True,\n",
    "    enable_thinking=False # Switches between thinking and non-thinking modes. Default is True.\n",
    ")\n",
    "model_inputs = tokenizer([text], return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "print(\"template loaded\")\n",
    "\n",
    "# conduct text completion\n",
    "generated_ids = model.generate(\n",
    "    **model_inputs,\n",
    "    max_new_tokens=32768\n",
    ")\n",
    "output_ids = generated_ids[0][len(model_inputs.input_ids[0]):].tolist() \n",
    "\n",
    "print(\"finish generating\")\n",
    "\n",
    "# parsing thinking content\n",
    "try:\n",
    "    # rindex finding 151668 (</think>)\n",
    "    index = len(output_ids) - output_ids[::-1].index(151668)\n",
    "except ValueError:\n",
    "    index = 0\n",
    "\n",
    "thinking_content = tokenizer.decode(output_ids[:index], skip_special_tokens=True).strip(\"\\n\")\n",
    "content = tokenizer.decode(output_ids[index:], skip_special_tokens=True).strip(\"\\n\")\n",
    "\n",
    "print(\"thinking content:\", thinking_content)\n",
    "print(\"content:\", content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98e4ee48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "\n",
    "# 加载罪名映射\n",
    "with open('dataset/st1/charges.json') as f:\n",
    "    charge_map = json.load(f)\n",
    "id_to_charge = {v: k for k, v in charge_map.items()}\n",
    "\n",
    "# 处理训练数据\n",
    "def process_data(file_path):\n",
    "    cases = []\n",
    "    with open(file_path) as f:\n",
    "        for line in f:\n",
    "            case = json.loads(line)\n",
    "            defendants = case['defendants']\n",
    "            charges = []\n",
    "            imprisonments = []\n",
    "            \n",
    "            for outcome in case['outcomes']:\n",
    "                charge_list = [j['standard_accusation'] for j in outcome['judgment'] if j['standard_accusation']]\n",
    "                imprisonment_list = [int(j['imprisonment']) if j['imprisonment'] else 0 \n",
    "                                   for j in outcome['judgment']]\n",
    "                \n",
    "                charges.append(charge_list)\n",
    "                imprisonments.append(imprisonment_list)\n",
    "            \n",
    "            cases.append({\n",
    "                'id': case.get('id', ''),\n",
    "                'fact': case['fact'],\n",
    "                'defendants': defendants,\n",
    "                'charges': charges,\n",
    "                'imprisonments': imprisonments\n",
    "            })\n",
    "    return cases\n",
    "\n",
    "train_data = process_data('dataset/st1/train.jsonl')\n",
    "test_data = process_data('dataset/st1/test.jsonl')\n",
    "\n",
    "# 构建标签矩阵\n",
    "def build_label_matrices(data):\n",
    "    charge_labels = []\n",
    "    imprisonment_labels = []\n",
    "    \n",
    "    for case in data:\n",
    "        case_charge_labels = []\n",
    "        case_imprisonment_labels = []\n",
    "        \n",
    "        for defendant_charges, defendant_imprisonments in zip(case['charges'], case['imprisonments']):\n",
    "            # 多标签罪名向量\n",
    "            charge_vec = [0] * len(charge_map)\n",
    "            for charge in defendant_charges:\n",
    "                if charge in charge_map:\n",
    "                    charge_vec[charge_map[charge]] = 1\n",
    "            \n",
    "            case_charge_labels.append(charge_vec)\n",
    "            case_imprisonment_labels.append(defendant_imprisonments)\n",
    "        \n",
    "        charge_labels.append(case_charge_labels)\n",
    "        imprisonment_labels.append(case_imprisonment_labels)\n",
    "    \n",
    "    return charge_labels, imprisonment_labels\n",
    "\n",
    "train_charge_labels, train_imprisonment_labels = build_label_matrices(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c7916816",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '',\n",
       " 'fact': '某市人民检察院指控，被告人郑某、谢某于2015年5月至9月6日间，在没有取得药品经营许可证的情况下，通过手机微信销售“香港威龙生物延时伟某某”。2015年9月6日21时许，郑某、谢某在帮顾客送货至某市池尾街道邮政局附近时被公安机关抓获，现场缴获“香港威龙生物延时伟某某”2盒，根据《中华人民共和国药品管理法》的规定，被查获的药品应认定为假药。某市人民检察院向法庭提供了作案地点、查获的药品的照片，提取笔录，扣押清单，食品药品监督管理部门出具的函复，被告人供述及户籍证明等证据。认为被告人郑某、谢某的行为触犯了《中华人民共和国刑法》x法条的规定，均已构成x罪。提请本院依法判处。被告人郑某、谢某对公诉机关指控的犯罪事实无异议。经审理查明，2015年5月至9月6日间，被告人郑某、谢某在没有取得药品经营许可证的情况下，通过手机微信销售“香港威龙生物延时伟某某”。2015年9月6日21时许，郑某、谢某为顾客送货至某市池尾街道邮政局附近时被公安机关抓获，现场缴获“香港威龙生物延时伟某某”2盒。经揭阳市食品药品监督管理局鉴定，查获的药品为假药。认定上述事实，有公诉机关提供并经庭审示证、质证，本院予以确认的下列证据证明：1.经被告人郑某、谢某确认无误的作案地点、查获药品的照片。2.提取笔录、扣押清单，证明：某市公安局于2015年9月6日在某市池尾街道邮政局附近，从郑某身上查获“香港威龙生物延时伟某某”2盒。3.揭阳市食品药品监督管理局出具的《关于＜委托鉴定函＞的函复》，证明：经鉴定，查获的“香港威龙生物延时伟某某”为假药。4.被告人郑某、谢某的供述，分别证明：他们两人是夫妻关系。2015年5月至9月6日间，郑某在没有取得药品经营许可证的情况下，通过手机微信销售“香港威龙生物延时伟某某”，已售出8盒。有两次是他们夫妻两个一起去送货给买家。2015年9月6日21时许，他们为顾客送货至某市池尾街道邮政局附近时被公安机关抓获。5.被告人郑某、谢某的户籍证明材料。',\n",
       " 'defendants': ['郑某', '谢某'],\n",
       " 'charges': [['生产、销售、提供假药罪'], ['生产、销售、提供假药罪']],\n",
       " 'imprisonments': [[6], [6]]}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3cae5781",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yunpeng/anaconda3/envs/anqi-lab/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch_geometric\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "# 构建案件事实图\n",
    "def build_fact_graph(fact, defendants):\n",
    "    # 使用依存分析构建图 (简化版)\n",
    "    nodes = defendants + ['PROSECUTOR', 'VICTIM', 'EVIDENCE']  # 添加法律角色\n",
    "    node_features = torch.randn(len(nodes), 128)  # 实际应使用法律实体嵌入\n",
    "    \n",
    "    # 创建边 (实际应使用句法分析)\n",
    "    edges = []\n",
    "    for i in range(len(nodes)):\n",
    "        for j in range(i+1, len(nodes)):\n",
    "            edges.append([i, j])\n",
    "    \n",
    "    edge_index = torch.tensor(edges, dtype=torch.long).t().contiguous()\n",
    "    return Data(x=node_features, edge_index=edge_index)\n",
    "\n",
    "# GNN编码器\n",
    "class LegalGNN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = torch_geometric.nn.GCNConv(128, 256)\n",
    "        self.conv2 = torch_geometric.nn.GCNConv(256, 512)\n",
    "    \n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = torch.relu(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e826d04e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModel, AutoTokenizer, TrainingArguments, Trainer\n",
    "\n",
    "class QwenLegalModel(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.qwen = AutoModel.from_pretrained(\"/home/yunpeng/lianqi/fnlp/JudgePred/model_zoo/Qwen3-8B\")\n",
    "        self.gnn = LegalGNN()\n",
    "        self.charge_classifier = torch.nn.Linear(512, len(charge_map))\n",
    "        self.imprisonment_predictor = torch.nn.Linear(512, 1)  # 预测单个罪名刑期\n",
    "    \n",
    "    def forward(self, input_ids, attention_mask, graph_data):\n",
    "        # 文本编码\n",
    "        text_emb = self.qwen(input_ids, attention_mask).last_hidden_state[:, 0, :]\n",
    "        \n",
    "        # 图编码\n",
    "        graph_emb = self.gnn(graph_data)\n",
    "        defendant_embs = graph_emb.x[:len(graph_data.defendants)]\n",
    "        \n",
    "        # 融合特征\n",
    "        fused_emb = torch.cat([text_emb, defendant_embs], dim=1)\n",
    "        \n",
    "        # 罪名预测\n",
    "        charge_logits = self.charge_classifier(fused_emb)\n",
    "        \n",
    "        # 刑期预测\n",
    "        imprisonment_preds = self.imprisonment_predictor(fused_emb)\n",
    "        \n",
    "        return charge_logits, imprisonment_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "00b85a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LegalLoss(torch.nn.Module):\n",
    "    def __init__(self, alpha=0.7):\n",
    "        super().__init__()\n",
    "        self.alpha = alpha  # 罪名损失权重\n",
    "        self.charge_loss = torch.nn.BCEWithLogitsLoss()\n",
    "        self.imprisonment_loss = torch.nn.L1Loss()  # MAE更适合刑期预测\n",
    "    \n",
    "    def forward(self, charge_logits, imprisonment_preds, charge_labels, imprisonment_labels):\n",
    "        # 罪名损失\n",
    "        charge_loss = self.charge_loss(charge_logits, charge_labels.float())\n",
    "        \n",
    "        # 刑期损失 (只计算实际存在的罪名)\n",
    "        imp_loss = 0\n",
    "        count = 0\n",
    "        for i, def_imprisonments in enumerate(imprisonment_labels):\n",
    "            for j, term in enumerate(def_imprisonments):\n",
    "                imp_loss += self.imprisonment_loss(imprisonment_preds[i][j], torch.tensor([term]).float())\n",
    "                count += 1\n",
    "        \n",
    "        imp_loss /= max(count, 1)  # 防止除零\n",
    "        \n",
    "        total_loss = self.alpha * charge_loss + (1 - self.alpha) * imp_loss\n",
    "        return total_loss, charge_loss, imp_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1db30b8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 7/7 [00:00<00:00, 124.29it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/tmp/ipykernel_1882579/1492525209.py\u001b[0m(20)\u001b[0;36mcollate_fn\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     18 \u001b[0;31m    \u001b[0;32mimport\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     19 \u001b[0;31m    \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 20 \u001b[0;31m    \u001b[0mfacts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'fact'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     21 \u001b[0;31m    \u001b[0mdefendants_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'defendants'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     22 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "<class 'list'>\n",
      "16\n",
      "{}\n",
      "{}\n"
     ]
    }
   ],
   "source": [
    "# 初始化模型\n",
    "model = QwenLegalModel()\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"/home/yunpeng/lianqi/fnlp/JudgePred/model_zoo/Qwen3-8B\")\n",
    "\n",
    "# 训练参数\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    num_train_epochs=5,\n",
    "    per_device_train_batch_size=2,  # 8张A100可调至4\n",
    "    gradient_accumulation_steps=8,\n",
    "    learning_rate=2e-5,\n",
    "    fp16=True,\n",
    "    logging_dir='./logs',\n",
    ")\n",
    "\n",
    "# 自定义数据收集函数\n",
    "def collate_fn(batch):\n",
    "    import pdb\n",
    "    pdb.set_trace()\n",
    "    facts = [item['fact'] for item in batch]\n",
    "    defendants_list = [item['defendants'] for item in batch]\n",
    "    \n",
    "    # 文本编码\n",
    "    text_encodings = tokenizer(facts, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "    \n",
    "    # 构建图数据\n",
    "    graph_data = [build_fact_graph(fact, defs) for fact, defs in zip(facts, defendants_list)]\n",
    "    \n",
    "    return {\n",
    "        'input_ids': text_encodings['input_ids'],\n",
    "        'attention_mask': text_encodings['attention_mask'],\n",
    "        'graph_data': graph_data,\n",
    "        'charge_labels': [item['charge_labels'] for item in batch],\n",
    "        'imprisonment_labels': [item['imprisonment_labels'] for item in batch]\n",
    "    }\n",
    "\n",
    "# 创建Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_data,\n",
    "    data_collator=collate_fn,\n",
    "    # compute_metrics=compute_metrics  # 需自定义评估函数\n",
    ")\n",
    "\n",
    "# 开始训练\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e1e2e69",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anqi-lab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
